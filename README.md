# Depression Detection Using Twitter Data
Depression Detection using Twitter data

1. [Project Motivation](#motivation)
2. [Proposed Model](#proposedModel)
2. [Dataset Construction](#dataset)
3. [Project Phases](#phases)
4. [Future Plan](#futureplan)
5. [Contributors](#contributors)
6. [Recources](#recources)



## Project Motivation <a name="motivation"></a>

As society becomes increasingly connected through technology, more people are engaging with the online world. However, this shift can lead to feelings of isolation, contributing to anxiety and depression.

Many individuals express their thoughts and emotions on social media platforms like Twitter, which offers a degree of anonymity. This openness provides an opportunity to detect emotional states through their tweets. From a medical perspective, identifying signs of depression through social media can help in offering appropriate support and guiding individuals towards recovery. For example, self-care chatbots like Woebot, which uses Cognitive Behavioral Therapy, can assist users in changing negative thought patterns and provide companionship during difficult times.

We also aim to create a dataset specifically designed for detecting depression in tweets, as our research indicates that such data is not readily available, presenting a significant challenge in developing this project.


## Proposed Model <a name="proposedModel"></a>

Our depression detection model can be integrated into existing products like GBoard on Android. GBoard, which uses federated learning to enhance user experience based on search history, could incorporate our model to detect signs of depression through user text input over time.

If depression is detected, it would be beneficial to suggest the use of a self-care chatbot while ensuring user privacy. This could be done by integrating the chatbot suggestion feature directly into GBoard, avoiding the need to send raw data back to a centralized server. Implementing federated learning along with local differential privacy will help protect user privacy.

We also aim to create a dedicated dataset for detecting depression in tweets, addressing the lack of available data and overcoming a major obstacle in our project.


<p align="center">
  <img width="489" height="355" src="https://user-images.githubusercontent.com/33187812/64063863-94c96580-cbfa-11e9-91be-b9b7bc6496e7.png">
</p>

##  Dataset Construction <a name="dataset"></a>

Constructing the dataset has been the most labor-intensive aspect of our project.

Initially, we used data from an existing GitHub repository [Detecting-Depression-in-Tweets](https://github.com/viritaromero/Detecting-Depression-in-Tweets). However, our initial model achieved over 99% accuracy during validation because the data was too simplistic, with most labeled depressive entries containing the word "depression".

So we decided to create our own twitter dataset for depression by using the third party tool, [TWINT](https://github.com/twintproject/twint).


### Collecting data   

We created a script (data_scraper.ipynb) to collect potentially depressive tweets by following these steps:

1. Used TWINT to collect tweets with hashtags such as
-    #depressed
-    #depression
-    #loneliness
-    #hopelessness1. 

2. Removed duplicate entries based on tweeter ID.

3. Remove entries that contain these positive or medical or educational sounding hashtags
-    #mentalhealth
-    #health
-    #happiness
-    #mentalillness
-    #happy
-    #joy
-    #wellbeing1. 

4. Filtered out tweets with more than three hashtags, @mentions, or URLs to avoid promotional messages
-  Containing more than three hashtags
-  Containing @mentions
-  Containing URLs

5. Excluded tweets with fewer than 25 characters or 5 words.

6. Removed all hashtags from the tweets to ensure the model focuses on the content rather than the presence of depressive hashtags.

The results are saved into csv files and allocated to our team members for review.


### Reviewing dataset

We manually reviewed the CSV files generated by the script. These files contained tweets with depressive hashtags, with a default target value of 1. We manually set non-depressive entries to 0 and removed non-English tweets.

The resulting dataset had a roughly 50-50 split of depressive and non-depressive tweets, providing a balanced resource to train our model to focus on tweet content.


### Additional Data Collection

We also gathered tweets representing non-depressive emotions like joy, love, surprise, and neutral content to ensure the dataset was comprehensive.


### Finalizing Dataset
We combined datasets from different sources to create a final, well-rounded dataset.

Although creating the dataset was time-consuming, it was crucial for developing an accurate depression detector that goes beyond mere sentiment analysis.


![Positive words](https://user-images.githubusercontent.com/14244685/63386084-108a0d80-c3c4-11e9-8735-77afc986cc33.png)
![negitive words](https://user-images.githubusercontent.com/14244685/63386087-108a0d80-c3c4-11e9-9796-588ce316ed70.png)



## Future Plan<a name="futureplan"></a>

- Use an external software such as liwc (http://liwc.wpengine.com/) to review the linguistic and emotional content of the tweets, and verify that the labels are correct.


## Resources<a name="resources"></a>
- Anne Bonner's Medium article [You Are What You Tweet](https://towardsdatascience.com/you-are-what-you-tweet-7e23fb84f4ed).
- [Sentiment Analysis â€” TorchText](https://medium.com/@sonicboom8/sentiment-analysis-torchtext-55fb57b1fab8)
- Pranjal Chaubey repo [Sixty AI](https://github.com/pranjalchaubey/Sixty-AI)



